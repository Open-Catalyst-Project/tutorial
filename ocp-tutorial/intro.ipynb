{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab8bd7bc",
   "metadata": {},
   "source": [
    "Utilizing large, graph-based, pre-trained  machine learned potentials in atomistic simulations \n",
    "----------\n",
    "\n",
    "# Abstract\n",
    "\n",
    "The most recent, state of the art machine learned potentials in atomistic simulations are based on graph models that are trained on large (1M+) datasets. These models can be downloaded and used in a wide array of applications ranging from catalysis to materials properties. These pre-trained models can be used on their own, to accelerate DFT calculation, and they can also be used as a starting point to fine-tune new models for specific tasks. In this workshop we will focus on large, graph-based, pre-trained  machine learned models from the Open Catalyst Project (OCP) to showcase how they can be used for these purposes. OCP provides several pre-trained models for a variety of tasks related to atomistic simulations. We will explain what these models are, how they differ, and details of the datasets they are trained from.  We will introduce an Atomic Simulation Environment (ase) calculator that leverages an OCP pre-trained model for typical simulation tasks including adsorbate geometry relaxation, adsorption energy calculations, and reaction energies. We will show how pre-trained models can be fine-tuned on new data sets for new tasks. We will also discuss current limitations of the models and opportunities for future research. Participants will need a laptop with internet capability. A computational environment accessible via the internet will be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9aeb9d",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Density functional theory (DFT) has been a mainstay in molecular simulation, but its high computational cost limits the number and size of simulations that are practical. Over the past two decades machine learning has increasingly been used to build surrogate models to supplement DFT. We call these models machine learned potentials (MLP) In the early days, neural networks were trained using the cartesian coordinates of atomistic systems as features with some success. These features lack important physical properties, notably they lack invariance to rotations, translations and permutations, and they are extensive features, which limit them to the specific system being investigated. About 15 years ago, a new set of features called symmetry functions were developed that were intensive, and which had these invariances. These functions enabled substantial progress in MLP, but they had a few important limitations. First, the size of the feature vector scaled quadratically with the number of elements, practically limiting the MLP to 4-5 elements. Second, composition was usually implicit in the functions, which limited the transferrability of the MLP to new systems. Finally, these functions were \"hand-crafted\", with limited or no adaptability to the systems being explored, thus one needed to use judgement and experience to select them. While progess has been made in mitigating these limitations, a new approach has overtaken these methods.\n",
    "\n",
    "Today, the state of the art in machine learned potentials uses graph convolutions to generate the feature vectors. In this approach, atomistic systems are represented as graphs where each node is an atom, and the edges connect the nodes (atoms) and roughly represent interactions or bonds between atoms. Then, there are machine learnable convolution functions that operate on the graph to generate feature vectors. These operators can work on pairs, triplets and quadruplets of nodes to compute \"messages\" that are passed to the central node (atom) and accumulated into the feature vector. This feature generate method can be constructed with all the desired invariances, the functions are machine learnable, and adapt to the systems being studied, and it scales well to high numbers of elements (the current models handle 50+ elements). These kind of MLPs began appearing regularly in the literature around 2016.\n",
    "\n",
    "Today an MLP consists of three things:\n",
    "\n",
    "1. A model that takes an atomistic system, generates features and relates those features to some output.\n",
    "2. A dataset that provides the atomistic systems and the desired output labels. This label could be energy, forces, or other atomistic properties.\n",
    "3. A checkpoint that stores the trained model for use in predictions.\n",
    "\n",
    "The [Open Catalyst Project (OCP)](https://github.com/Open-Catalyst-Project) is an umbrella for these machine learned potential models, data sets, and checkpoints from training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3b0489",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "OCP provides several [models](https://github.com/Open-Catalyst-Project/ocp/blob/main/MODELS.md). Each model represents a different approach to featurization, and a different machine learning architecture. The models can be used for different tasks, and you will find different checkpoints associated with different datasets and tasks. \n",
    "\n",
    "- CGCNN [[`arXiv`](https://arxiv.org/abs/1710.10324)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/blob/main/ocpmodels/models/cgcnn.py)]\n",
    "- SchNet [[`arXiv`](https://arxiv.org/abs/1706.08566)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/blob/main/ocpmodels/models/schnet.py)]\n",
    "- DimeNet [[`arXiv`](https://arxiv.org/abs/2003.03123)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/blob/main/ocpmodels/models/dimenet.py)]\n",
    "- ForceNet [[`arXiv`](https://arxiv.org/abs/2103.01436)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/blob/main/ocpmodels/models/forcenet.py)]\n",
    "- DimeNet++ [[`arXiv`](https://arxiv.org/abs/2011.14115)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/blob/main/ocpmodels/models/dimenet_plus_plus.py)]\n",
    "- SpinConv [[`arXiv`](https://arxiv.org/abs/2106.09575)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/blob/main/ocpmodels/models/spinconv.py)]\n",
    "- GemNet-dT [[`arXiv`](https://arxiv.org/abs/2106.08903)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/tree/main/ocpmodels/models/gemnet)]\n",
    "- PaiNN [[`arXiv`](https://arxiv.org/abs/2102.03150)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/tree/main/ocpmodels/models/painn)]\n",
    "- Graph Parallelism [[`arXiv`](https://arxiv.org/abs/2203.09697)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/tree/main/ocpmodels/models/gemnet_gp)]\n",
    "- GemNet-OC [[`arXiv`](https://arxiv.org/abs/2204.02782)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/tree/main/ocpmodels/models/gemnet_oc)]\n",
    "- SCN [[`arXiv`](https://arxiv.org/abs/2206.14331)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/tree/main/ocpmodels/models/scn)]\n",
    "- eSCN [[`arXiv`](https://arxiv.org/abs/2302.03655)] [[`code`](https://github.com/Open-Catalyst-Project/ocp/tree/main/ocpmodels/models/escn)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfbef8",
   "metadata": {},
   "source": [
    "## Datasets / Tasks\n",
    "\n",
    "OCP provides several different [datasets](https://github.com/Open-Catalyst-Project/ocp/blob/main/DATASET.md) that correspond to different tasks that range from predicting energy and forces from structures to Bader charges, relaxation energies, and others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f80327",
   "metadata": {},
   "source": [
    "## Checkpoints\n",
    "\n",
    "To use a pre-trained model you need to have [ocp](https://github.com/Open-Catalyst-Project/ocp) installed. Then you need to choose a checkpoint and config file which will be loaded to configure OCP for the predictions you want to make. There are two approaches to running OCP, via scripts in a shell, or using an ASE compatible calculator.\n",
    "\n",
    "We will focus on the ASE compatible calculator here. To facilitate using the checkpoints, there is a set of [utilities](./ocp-tutorial.ipynb) for this tutorial. You can list the checkpoints that are readily available here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b55791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switched to branch 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n",
      "Obtaining file:///home/jovyan/shared-scratch/jkitchin/tutorial/ocp-tutorial/ocp\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: ocp-models\n",
      "  Building editable for ocp-models (pyproject.toml): started\n",
      "  Building editable for ocp-models (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ocp-models: filename=ocp_models-0.0.3-0.editable-py3-none-any.whl size=3331 sha256=3c311fbde85c133b039e08e457fdf1649eb4b818df3d84e6297369083f16b71d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nb2ccc26/wheels/07/ee/07/0e00e8ad812bce6577c83a5a2463f047a87819e9eec1cc3a4b\n",
      "Successfully built ocp-models\n",
      "Installing collected packages: ocp-models\n",
      "  Attempting uninstall: ocp-models\n",
      "    Found existing installation: ocp-models 0.0.3\n",
      "    Uninstalling ocp-models-0.0.3:\n",
      "      Successfully uninstalled ocp-models-0.0.3\n",
      "Successfully installed ocp-models-0.0.3\n",
      "d2105bcd6ad6615a345ea319b0e4aaa841c79475\n",
      "Restart the kernel\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "[ ! -d \"ocp\" ] && git clone https://github.com/Open-Catalyst-Project/ocp.git\n",
    "\n",
    "cd ocp\n",
    "git pull\n",
    "git checkout main\n",
    "pip install -e .\n",
    "git rev-parse HEAD\n",
    "echo \"Restart the kernel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25e4efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See https://github.com/Open-Catalyst-Project/ocp/blob/main/MODELS.md for more details.\n",
      "CGCNN 200k\n",
      "CGCNN 2M\n",
      "CGCNN 20M\n",
      "CGCNN All\n",
      "DimeNet 200k\n",
      "DimeNet 2M\n",
      "SchNet 200k\n",
      "SchNet 2M\n",
      "SchNet 20M\n",
      "SchNet All\n",
      "DimeNet++ 200k\n",
      "DimeNet++ 2M\n",
      "DimeNet++ 20M\n",
      "DimeNet++ All\n",
      "SpinConv 2M\n",
      "SpinConv All\n",
      "GemNet-dT 2M\n",
      "GemNet-dT All\n",
      "PaiNN All\n",
      "GemNet-OC 2M\n",
      "GemNet-OC All\n",
      "GemNet-OC All+MD\n",
      "GemNet-OC-Large All+MD\n",
      "SCN 2M\n",
      "SCN-t4-b2 2M\n",
      "SCN All+MD\n",
      "eSCN-L4-M2-Lay12 2M\n",
      "eSCN-L6-M2-Lay12 2M\n",
      "eSCN-L6-M2-Lay12 All+MD\n",
      "eSCN-L6-M3-Lay20 All+MD\n",
      "EquiformerV2 (83M) 2M\n",
      "EquiformerV2 (31M) All+MD\n",
      "EquiformerV2 (153M) All+MD\n",
      "GemNet-dT OC22\n",
      "GemNet-OC OC22\n",
      "GemNet-OC OC20+OC22\n",
      "GemNet-OC trained with `enforce_max_neighbors_strictly=False` #467 OC20+OC22\n",
      "GemNet-OC OC20->OC22\n",
      "Copy one of these keys to get_checkpoint(key) to download it.\n"
     ]
    }
   ],
   "source": [
    "%run ocp-tutorial.ipynb\n",
    "\n",
    "list_checkpoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f1ddc",
   "metadata": {},
   "source": [
    "You can get a checkpoint file with one of the keys listed above like this. The resulting string is the name of the file downloaded, and you use that when creating an OCP calculator later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45f250f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gnoc_oc22_oc20_all_s2ef.pt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = get_checkpoint('GemNet-OC OC20+OC22')\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db877425",
   "metadata": {},
   "source": [
    "# Goals for this tutorial\n",
    "\n",
    "This tutorial will start by using OCP in a Jupyter notebook to setup some simple calculations that use OCP to compute energy and forces, for structure optimization, and then an example of fine-tuning a model with new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
